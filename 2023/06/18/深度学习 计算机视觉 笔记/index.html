

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/Github.png">
  <link rel="icon" href="/img/Github.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Ling yi">
  <meta name="keywords" content="">
  
    <meta name="description" content="教程 https:&#x2F;&#x2F;zh-v2.d2l.ai&#x2F;chapter_preface&#x2F;index.html">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习 计算机视觉 笔记">
<meta property="og:url" content="https://anonymouslosty.github.io/2023/06/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%20%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="anonymouslosty的Blog">
<meta property="og:description" content="教程 https:&#x2F;&#x2F;zh-v2.d2l.ai&#x2F;chapter_preface&#x2F;index.html">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://anonymouslosty.github.io/img/r-cnn.svg">
<meta property="og:image" content="https://anonymouslosty.github.io/img/ssd.svg">
<meta property="og:image" content="https://zh-v2.d2l.ai/_images/trans_conv.svg">
<meta property="og:image" content="https://anonymouslosty.github.io/img/transposed-conv1.png">
<meta property="og:image" content="https://anonymouslosty.github.io/img/transposed-conv2.png">
<meta property="og:image" content="https://anonymouslosty.github.io/img/transposed-conv3.png">
<meta property="og:image" content="https://anonymouslosty.github.io/img/neural-style.svg">
<meta property="article:published_time" content="2023-06-18T05:30:57.000Z">
<meta property="article:modified_time" content="2023-07-04T16:27:52.540Z">
<meta property="article:author" content="Ling yi">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://anonymouslosty.github.io/img/r-cnn.svg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>深度学习 计算机视觉 笔记 - anonymouslosty的Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"anonymouslosty.github.io","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":90,"cursorChar":"..","loop":true,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4","placement":"left","visible":"hover","icon":"#"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":true,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4","collapseDepth":2},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 80vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>anonymouslosty的Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/band_deer.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="深度学习 计算机视觉 笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Ling yi
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-06-18 13:30" pubdate>
          2023年6月18日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          19k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          157 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

    <a target="_blank" rel="noopener" href="https://github.com/anonymouslosty" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0; z-index: 1031;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">深度学习 计算机视觉 笔记</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2023年7月5日 凌晨
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="边缘框">边缘框</h2>
<p><strong>实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">box_corner_to_center</span>(<span class="hljs-params">boxes</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;从（左上，右下）转换到（中间，宽度，高度）&quot;&quot;&quot;</span><br>    x1, y1, x2, y2 = boxes[:, <span class="hljs-number">0</span>], boxes[:, <span class="hljs-number">1</span>], boxes[:, <span class="hljs-number">2</span>], boxes[:, <span class="hljs-number">3</span>]<br>    cx = (x1 + x2) / <span class="hljs-number">2</span><br>    cy = (y1 + y2) / <span class="hljs-number">2</span><br>    w = x2 - x1<br>    h = y2 - y1<br>    boxes = torch.stack((cx, cy, w, h), axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> boxes<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">box_center_to_corner</span>(<span class="hljs-params">boxes</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;从（中间，宽度，高度）转换到（左上，右下）&quot;&quot;&quot;</span><br>    cx, cy, w, h = boxes[:, <span class="hljs-number">0</span>], boxes[:, <span class="hljs-number">1</span>], boxes[:, <span class="hljs-number">2</span>], boxes[:, <span class="hljs-number">3</span>]<br>    x1 = cx - <span class="hljs-number">0.5</span> * w<br>    y1 = cy - <span class="hljs-number">0.5</span> * h<br>    x2 = cx + <span class="hljs-number">0.5</span> * w<br>    y2 = cy + <span class="hljs-number">0.5</span> * h<br>    boxes = torch.stack((x1, y1, x2, y2), axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> boxes<br><br><span class="hljs-comment"># 添加到图里</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox_to_rect</span>(<span class="hljs-params">bbox, color</span>):<br>    <span class="hljs-comment"># 将边界框(左上x,左上y,右下x,右下y)格式转换成matplotlib格式：</span><br>    <span class="hljs-comment"># ((左上x,左上y),宽,高)</span><br>    <span class="hljs-keyword">return</span> d2l.plt.Rectangle(<br>        xy=(bbox[<span class="hljs-number">0</span>], bbox[<span class="hljs-number">1</span>]), width=bbox[<span class="hljs-number">2</span>]-bbox[<span class="hljs-number">0</span>], height=bbox[<span class="hljs-number">3</span>]-bbox[<span class="hljs-number">1</span>],<br>        fill=<span class="hljs-literal">False</span>, edgecolor=color, linewidth=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<p><strong>执行</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># bbox是边界框的英文缩写</span><br>dog_bbox, cat_bbox = [<span class="hljs-number">60.0</span>, <span class="hljs-number">45.0</span>, <span class="hljs-number">378.0</span>, <span class="hljs-number">516.0</span>], [<span class="hljs-number">400.0</span>, <span class="hljs-number">112.0</span>, <span class="hljs-number">655.0</span>, <span class="hljs-number">493.0</span>]<br>fig = d2l.plt.imshow(img)<br>fig.axes.add_patch(bbox_to_rect(dog_bbox, <span class="hljs-string">&#x27;blue&#x27;</span>))<br>fig.axes.add_patch(bbox_to_rect(cat_bbox, <span class="hljs-string">&#x27;red&#x27;</span>));<br></code></pre></td></tr></table></figure>
<h2 id="锚框">锚框</h2>
<h3 id="原理">原理</h3>
<h4 id="锚框与边框">锚框与边框</h4>
<ul>
<li>边框 bounding box bbx 真实值</li>
<li>锚框：预测框</li>
</ul>
<h4 id="特点">特点</h4>
<ul>
<li>是一类目标检测算法</li>
<li>提出多个被称为锚框的区域</li>
<li>预测每个锚框内是否含有关注的物体</li>
<li>如果是，预测从这个锚框到真实边缘框的偏移</li>
</ul>
<h4 id="iou-交并比">IoU 交并比</h4>
<ul>
<li>衡量两个框之间的相似度</li>
<li>约定两个集合<code>A</code>,<code>B</code>
<ul>
<li><span class="math display">\[J(A,B)=\frac{|\mathbf A\cap \mathbf
B|}{|\mathbf A\cup \mathbf B|}\]</span></li>
<li>0表示有无重叠，1表示有重叠</li>
</ul></li>
</ul>
<h4 id="赋予锚框标号">赋予锚框标号</h4>
<ul>
<li>每个锚框是一个训练样本</li>
<li>每个锚框，要么标注成背景，要么关联上一个真实边缘框</li>
<li>缺点
<ul>
<li>可能会生成大量的锚框，导致大量的负类样本</li>
</ul></li>
</ul>
<h4 id="使用非极大值nms抑制输出">使用非极大值(NMS)抑制输出</h4>
<ul>
<li>每个锚框预测一个边缘框</li>
<li>NMS可以合并相似的预测
<ul>
<li>选中是非背景类的最大预测值</li>
<li>去掉所有其它和它IoU值大于<span
class="math inline">\(\theta\)</span>的预测</li>
<li>重复上述过程，要么预测被选中，要么被去掉</li>
</ul></li>
</ul>
<h4 id="锚框生成方式">锚框生成方式</h4>
<ul>
<li>以每一个像素为中心</li>
<li>生成不同高度、宽度的锚框
<ul>
<li><strong>锚框的宽度和高度分别为<span
class="math inline">\(ws\sqrt{r}\)</span>和<span
class="math inline">\(hs/\sqrt{r}\)</span></strong></li>
</ul></li>
<li><code>s</code>和<code>r</code>的取值，不是阶乘组合，而是<strong>只考虑包含s1或者r1的组合</strong>
<ul>
<li><code>n+m-1</code> <code>size+ratio-1</code></li>
<li><span class="math inline">\((s_1, r_1), (s_1, r_2), \ldots, (s_1,
r_m), (s_2, r_1), (s_3, r_1), \ldots, (s_n, r_1).\)</span></li>
</ul></li>
</ul>
<h4 id="总结">总结</h4>
<ul>
<li>一类目标检测算法基于锚框来预测</li>
<li>首先生成大量锚框，并赋予标号，每个锚框作为一个样本进行训练</li>
<li>在预测时，使用NMS来去掉冗余的预测</li>
</ul>
<h3 id="代码实现">代码实现</h3>
<p><strong>引入库并设置精度</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>torch.set_printoptions(<span class="hljs-number">2</span>)  <span class="hljs-comment"># 精简输出精度</span><br></code></pre></td></tr></table></figure>
<p><strong>锚框的宽度和高度分别为<span
class="math inline">\(ws\sqrt{r}\)</span>和<span
class="math inline">\(hs/\sqrt{r}\)</span></strong></p>
<ul>
<li><code>w</code>照片宽度，<code>h</code>照片高度</li>
<li><code>s</code> :scale，锚框占照片大小的百分比</li>
<li><code>r</code>：ratio ，锚框的高宽比</li>
</ul>
<h2 id="物体检测算法">物体检测算法</h2>
<h3 id="r-cnn">R-CNN</h3>
<p>Region-CNN</p>
<figure>
<img src="/img/r-cnn.svg" srcset="/img/loading.gif" lazyload alt="r-cnn" />
<figcaption aria-hidden="true">r-cnn</figcaption>
</figure>
<h4 id="特点-1">特点</h4>
<ul>
<li>使用启发式搜索算法<code>selective search</code>来选择锚框</li>
<li>使用预训练模型<code>pretraining-mode</code>对每个锚框抽取特征</li>
<li>训练一个SVM来对类别分类</li>
<li>训练一个线性回归模型来预测边缘框偏移</li>
</ul>
<p>一个图片变为一千张小图片 ，计算量很大</p>
<h4 id="roi-pooling-兴趣区域池化层">RoI Pooling 兴趣区域池化层</h4>
<ul>
<li>给定一个锚框，均匀分割为<code>nxm</code>块，输出每块里的最大值。
<ul>
<li>每个锚框的大小不同，但是作为分类依据的时候需要变为相同的大小，作为<code>batch</code></li>
</ul></li>
<li>不管锚框多大，总是输出<code>nm</code>个值</li>
</ul>
<h4 id="具体流程">具体流程</h4>
<ol type="1">
<li>对输入图像使用<em>选择性搜索</em>来选取多个高质量的提议区域(<code>proposal region</code>)
(<a
target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#id172">Uijlings
<em>et al.</em>,
2013</a>)。这些提议区域通常是在多个尺度下选取的，并具有不同的形状和大小。每个提议区域都将被标注类别和真实边界框；</li>
<li>选择一个预训练的卷积神经网络，并将其在输出层之前截断。将每个提议区域变形为网络需要的输入尺寸(<code>RoI Pooling</code>)，并通过前向传播输出抽取的提议区域特征；</li>
<li>将每个提议区域的特征连同其标注的类别作为一个样本。训练多个支持向量机对目标分类，其中每个支持向量机用来判断样本是否属于某一个类别；</li>
<li>将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。</li>
</ol>
<h3 id="fast-rcnn">Fast RCNN</h3>
<h4 id="特点-2">特点</h4>
<ul>
<li>使用CNN对图片进行特征抽取</li>
<li>使用ROI池化层对每个锚框生成固定长度特征</li>
</ul>
<h3 id="ssd">SSD</h3>
<h4 id="结构">结构</h4>
<figure>
<img src="/img/ssd.svg" srcset="/img/loading.gif" lazyload alt="ssd" />
<figcaption aria-hidden="true">ssd</figcaption>
</figure>
<h5 id="基础网络块">基础网络块</h5>
<p>​ 2 x 3 x 256 x 256 --&gt; 2 x 64 x 32 x 32
<strong>作用：抽特征，获取feature map(Y)</strong> 2 x 64 x 32 x 32</p>
<h5 id="锚框生成">锚框生成</h5>
<p>​ multibox_prior(data,size,ratio)
<strong>作用：根据data的高、宽以及锚框的size ratio生成锚框</strong> 32 x
32 x (3+2-1)</p>
<h5 id="类别预测">类别预测</h5>
<p>​ cls_predictor(Y) <strong>作用：根据feature
map预测每个像素的锚框可能的类别</strong> 32 x 32 x (3+2-1) x (1+1)</p>
<h5 id="边界预测">边界预测</h5>
<p>​ box_predictor(Y) <strong>作用：根据feature map
预测每个锚框的位置</strong> 32 x 32 x (3+2-1) x 4</p>
<h5 id="理解">理解</h5>
<ul>
<li><p>特征图 2 x 64 x 32 x 32</p></li>
<li><p>用 cls_predictor Conv2d(64,8,kernel=3,padding=1)
从特征图中抽出8类作为新的特征</p>
<ul>
<li>输出通道为8，8个滤波器</li>
<li>每个滤波器 卷积核 3 x 3 x 64</li>
<li>专门抽类别特征的，卷积核里的参数慢慢训练为可以做类别分类的</li>
</ul></li>
<li><p>用 box_predictor Conv2d(64,16,kernel=3,padding=1)
从特征图中抽出16个偏置(4x4)作为新的特征</p>
<ul>
<li>输出通道为16，16个滤波器</li>
<li>每个滤波器 卷积核 3 x 3 x 64</li>
<li>专门抽偏置特征的，卷积核里的参数慢慢训练为可以获取偏置的</li>
</ul></li>
<li><p>无论输入图像的通道是多少，每经过一个滤波器都将生成一个通道为1的特征图。</p></li>
<li><p>一个卷积层之内可定义多个滤波器，当前卷积层上的各个滤波器会对上一层输入的每个feature
map（特征图）分别执行卷积操作，即每个滤波器都会对应生成一个新的特征图feature
map(不同的滤波器所提取的特征不同)。</p></li>
<li><p>故而在下一层需要多少个特征图，本层就需要定义多少个滤波器，即滤波器的个数与传出的特征图的张数一致。</p></li>
</ul>
<h4 id="代码">代码</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># num_anchors 每个像素的对应生成的锚框个数</span><br><span class="hljs-comment"># num_classes 预测的类别数</span><br><span class="hljs-comment"># num_anchors *(num_classes+1) 所有锚框所有预测的类别</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cls_predictor</span>(<span class="hljs-params">num_inputs, num_anchors, num_classes</span>):<br>    <span class="hljs-keyword">return</span> nn.Conv2d(num_inputs, num_anchors * (num_classes + <span class="hljs-number">1</span>),<br>                     kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 预测和正确的bbx的偏移</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox_predictor</span>(<span class="hljs-params">num_inputs, num_anchors</span>):<br>    <span class="hljs-keyword">return</span> nn.Conv2d(num_inputs, num_anchors * <span class="hljs-number">4</span>, <br>                     kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通道数挪到最后，然后flatten</span><br><span class="hljs-comment"># start_dim = 1 把后面三个维度拉成一个向量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">flatten_pred</span>(<span class="hljs-params">pred</span>):<br>    <span class="hljs-keyword">return</span> torch.flatten(pred.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>), start_dim=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 拉成向量之后在第一个维度拼接</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">concat_preds</span>(<span class="hljs-params">preds</span>):<br>    <span class="hljs-keyword">return</span> torch.cat([flatten_pred(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> preds], dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 改变输出通道的数量 高宽减半块</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">down_sample_blk</span>(<span class="hljs-params">in_channels, out_channels</span>):<br>    blk = []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>        blk.append(nn.Conv2d(in_channels, out_channels,<br>                             <span class="hljs-comment"># 不改变高宽</span><br>                             kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br>        blk.append(nn.BatchNorm2d(out_channels))<br>        blk.append(nn.ReLU())<br>        in_channels = out_channels<br>    <span class="hljs-comment"># 用最大池化层把高宽减半</span><br>    blk.append(nn.MaxPool2d(<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> nn.Sequential(*blk)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 基本网络块</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">base_net</span>():<br>    blk = []<br>    num_filters = [<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num_filters) - <span class="hljs-number">1</span>):<br>        blk.append(down_sample_blk(num_filters[i], num_filters[i+<span class="hljs-number">1</span>]))<br>    <span class="hljs-keyword">return</span> nn.Sequential(*blk)<br><br><span class="hljs-comment"># 3 -&gt; 16 -&gt; 32 -&gt; 64</span><br><span class="hljs-comment"># 256 / 2^3 = 32</span><br>forward(torch.zeros((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>)), base_net()).shape<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 整体模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_blk</span>(<span class="hljs-params">i</span>):<br>    <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>        blk = base_net()<br>    <span class="hljs-keyword">elif</span> i == <span class="hljs-number">1</span>:<br>        blk = down_sample_blk(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)<br>    <span class="hljs-keyword">elif</span> i == <span class="hljs-number">4</span>:<br>        <span class="hljs-comment"># 最后，把feature map变为 1x1 </span><br>        blk = nn.AdaptiveMaxPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">else</span>:<br>        blk = down_sample_blk(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br>    <span class="hljs-keyword">return</span> blk<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义前向计算 包含锚框处理的前向计算</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">blk_forward</span>(<span class="hljs-params">X, blk, size, ratio, cls_predictor, bbox_predictor</span>):<br>    <span class="hljs-comment"># 计算当前stage的 feature map</span><br>    Y = blk(X)<br>    <span class="hljs-comment"># 计算锚框</span><br>    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)<br>    cls_preds = cls_predictor(Y)<br>    bbox_preds = bbox_predictor(Y)<br>    <span class="hljs-comment"># 返回当前stage卷积层的输出 feature map</span><br>    <span class="hljs-comment"># 卷积层输出上面的锚框</span><br>    <span class="hljs-comment"># 对每一个锚框类别的预测</span><br>    <span class="hljs-comment"># 每一个锚框对真实的锚框的偏移值的预测</span><br>    <span class="hljs-keyword">return</span> (Y, anchors, cls_preds, bbox_preds)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义超参数</span><br>sizes = [[<span class="hljs-number">0.2</span>, <span class="hljs-number">0.272</span>], <span class="hljs-comment"># stage 1</span><br>         [<span class="hljs-number">0.37</span>, <span class="hljs-number">0.447</span>], <br>         [<span class="hljs-number">0.54</span>, <span class="hljs-number">0.619</span>], <br>         [<span class="hljs-number">0.71</span>, <span class="hljs-number">0.79</span>], <br>         [<span class="hljs-number">0.88</span>, <span class="hljs-number">0.961</span>]]<span class="hljs-comment"># stage 5 锚框覆盖96%</span><br>ratios = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.5</span>]] * <span class="hljs-number">5</span><br>num_anchors = <span class="hljs-built_in">len</span>(sizes[<span class="hljs-number">0</span>]) + <span class="hljs-built_in">len</span>(ratios[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义完整网络</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TinySSD</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(TinySSD, self).__init__(**kwargs)<br>        self.num_classes = num_classes<br>        idx_to_in_channels = [<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            <span class="hljs-comment"># 定义每个 stage blk、cls、bbx_predictor</span><br>            <span class="hljs-comment"># 即赋值语句self.blk_i=get_blk(i)</span><br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">f&#x27;blk_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, get_blk(i))<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">f&#x27;cls_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, cls_predictor(idx_to_in_channels[i],<br>                                                    num_anchors, num_classes))<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">f&#x27;bbox_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, bbox_predictor(idx_to_in_channels[i],<br>                                                      num_anchors))<br>    <span class="hljs-comment"># 完整的forward函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        anchors, cls_preds, bbox_preds = [<span class="hljs-literal">None</span>] * <span class="hljs-number">5</span>, [<span class="hljs-literal">None</span>] * <span class="hljs-number">5</span>, [<span class="hljs-literal">None</span>] * <span class="hljs-number">5</span><br>        <span class="hljs-comment"># 5 个 stage</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            <span class="hljs-comment"># 拿到每一步blk_forward()的值</span><br>            <span class="hljs-comment"># getattr(self,&#x27;blk_%d&#x27;%i)即访问self.blk_i</span><br>            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(<br>                X, <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;blk_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>), sizes[i], ratios[i],<br>                <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;cls_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>), <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;bbox_<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>))<br>        anchors = torch.cat(anchors, dim=<span class="hljs-number">1</span>)<br>        cls_preds = concat_preds(cls_preds)<br>        cls_preds = cls_preds.reshape(<br>            cls_preds.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>, self.num_classes + <span class="hljs-number">1</span>)<br>        bbox_preds = concat_preds(bbox_preds)<br>        <span class="hljs-comment"># 返回每一个层的Anchors 类别的预测和bbox的预测</span><br>        <span class="hljs-keyword">return</span> anchors, cls_preds, bbox_preds<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">net = TinySSD(num_classes=<span class="hljs-number">1</span>)<br>X = torch.zeros((<span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>))<br>anchors, cls_preds, bbox_preds = net(X)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;output anchors:&#x27;</span>, anchors.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;output class preds:&#x27;</span>, cls_preds.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;output bbox preds:&#x27;</span>, bbox_preds.shape)<br><br><span class="hljs-comment"># 一共有 5444 个锚框 每个锚框由4个值确定</span><br><span class="hljs-comment">#output anchors: torch.Size([1, 5444, 4])</span><br><span class="hljs-comment"># 32个 批次 5444 个锚框 每个锚框 2 个类别</span><br><span class="hljs-comment">#output class preds: torch.Size([32, 5444, 2])</span><br><span class="hljs-comment"># 32个 批次 5444 个锚框 每个锚框的4个确定位置的值离真实bbx的偏移</span><br><span class="hljs-comment">#output bbox preds: torch.Size([32, 21776])</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练</span><br>batch_size = <span class="hljs-number">32</span><br>train_iter, _ = d2l.load_data_bananas(batch_size)<br><br>device, net = d2l.try_gpu(), TinySSD(num_classes=<span class="hljs-number">1</span>)<br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.2</span>, weight_decay=<span class="hljs-number">5e-4</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br><span class="hljs-comment"># 其中包含了类的预测和损失函数的预测</span><br><br>cls_loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><span class="hljs-comment"># 做减法取绝对值 防止距离过大导致损失过大</span><br><span class="hljs-comment"># 弃疗了，预测很差的锚框不需要，所以不需要这种损失算出来很大的锚框</span><br><span class="hljs-comment"># 也不需要算很大的损失</span><br>bbox_loss = nn.L1Loss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calc_loss</span>(<span class="hljs-params">cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks</span>):<br>    batch_size, num_classes = cls_preds.shape[<span class="hljs-number">0</span>], cls_preds.shape[<span class="hljs-number">2</span>]<br>    cls = cls_loss(cls_preds.reshape(-<span class="hljs-number">1</span>, num_classes),<br>                   cls_labels.reshape(-<span class="hljs-number">1</span>)).reshape(batch_size, -<span class="hljs-number">1</span>).mean(dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># mask 当锚框为背景框的时候就不用预测偏倚</span><br>    bbox = bbox_loss(bbox_preds * bbox_masks,<br>                     bbox_labels * bbox_masks).mean(dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> cls + bbox<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cls_eval</span>(<span class="hljs-params">cls_preds, cls_labels</span>):<br>    <span class="hljs-comment"># 由于类别预测结果放在最后一维，argmax需要指定最后一维。</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>((cls_preds.argmax(dim=-<span class="hljs-number">1</span>).<span class="hljs-built_in">type</span>(<br>        cls_labels.dtype) == cls_labels).<span class="hljs-built_in">sum</span>())<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox_eval</span>(<span class="hljs-params">bbox_preds, bbox_labels, bbox_masks</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>((torch.<span class="hljs-built_in">abs</span>((bbox_labels - bbox_preds) * bbox_masks)).<span class="hljs-built_in">sum</span>())<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型训练</span><br>num_epochs, timer = <span class="hljs-number">20</span>, d2l.Timer()<br>animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs],<br>                        legend=[<span class="hljs-string">&#x27;class error&#x27;</span>, <span class="hljs-string">&#x27;bbox mae&#x27;</span>])<br>net = net.to(device)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-comment"># 训练精确度的和，训练精确度的和中的示例数</span><br>    <span class="hljs-comment"># 绝对误差的和，绝对误差的和中的示例数</span><br>    metric = d2l.Accumulator(<span class="hljs-number">4</span>)<br>    net.train()<br>    <span class="hljs-keyword">for</span> features, target <span class="hljs-keyword">in</span> train_iter:<br>        timer.start()<br>        trainer.zero_grad()<br>        <span class="hljs-comment"># Y 真实的物体的bbx</span><br>        <span class="hljs-comment"># 不能直接预测Y 要预测锚对应的类别和与真实bbx之间的偏移量</span><br>        X, Y = features.to(device), target.to(device)<br>        <span class="hljs-comment"># 生成多尺度的锚框，为每个锚框预测类别和偏移量</span><br>        anchors, cls_preds, bbox_preds = net(X)<br>        <span class="hljs-comment"># 为每个锚框标注类别和偏移量</span><br>        bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y)<br>        <span class="hljs-comment"># 根据类别和偏移量的预测和标注值计算损失函数</span><br>        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,<br>                      bbox_masks)<br>        l.mean().backward()<br>        trainer.step()<br>        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),<br>                   bbox_eval(bbox_preds, bbox_labels, bbox_masks),<br>                   bbox_labels.numel())<br>    cls_err, bbox_mae = <span class="hljs-number">1</span> - metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>], metric[<span class="hljs-number">2</span>] / metric[<span class="hljs-number">3</span>]<br>    animator.add(epoch + <span class="hljs-number">1</span>, (cls_err, bbox_mae))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;class err <span class="hljs-subst">&#123;cls_err:<span class="hljs-number">.2</span>e&#125;</span>, bbox mae <span class="hljs-subst">&#123;bbox_mae:<span class="hljs-number">.2</span>e&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_iter.dataset) / timer.stop():<span class="hljs-number">.1</span>f&#125;</span> examples/sec on &#x27;</span><br>      <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torchvision.io.read_image(<span class="hljs-string">&#x27;../data/banana.jpg&#x27;</span>).unsqueeze(<span class="hljs-number">0</span>).<span class="hljs-built_in">float</span>()<br>img = X.squeeze(<span class="hljs-number">0</span>).permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).long()<br><span class="hljs-comment"># 预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">X</span>):<br>    net.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># 预测模式</span><br>    anchors, cls_preds, bbox_preds = net(X.to(device))<br>    cls_probs = F.softmax(cls_preds, dim=<span class="hljs-number">2</span>).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)<br>    idx = [i <span class="hljs-keyword">for</span> i, row <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(output[<span class="hljs-number">0</span>]) <span class="hljs-keyword">if</span> row[<span class="hljs-number">0</span>] != -<span class="hljs-number">1</span>]<br>    <span class="hljs-comment"># 只保留NMS留下的idx</span><br>    <span class="hljs-keyword">return</span> output[<span class="hljs-number">0</span>, idx]<br><br>output = predict(X)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">display</span>(<span class="hljs-params">img, output, threshold</span>):<br>    d2l.set_figsize((<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>    fig = d2l.plt.imshow(img)<br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> output:<br>        score = <span class="hljs-built_in">float</span>(row[<span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">if</span> score &lt; threshold:<br>            <span class="hljs-keyword">continue</span><br>        h, w = img.shape[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]<br>        bbox = [row[<span class="hljs-number">2</span>:<span class="hljs-number">6</span>] * torch.tensor((w, h, w, h), device=row.device)]<br>        d2l.show_bboxes(fig.axes, bbox, <span class="hljs-string">&#x27;%.2f&#x27;</span> % score, <span class="hljs-string">&#x27;w&#x27;</span>)<br><br>display(img, output.cpu(), threshold=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<h3 id="语义分割">语义分割</h3>
<h4 id="转置卷积">转置卷积</h4>
<h5 id="特点-3">特点</h5>
<ul>
<li>普通卷积算子不会<strong>增大</strong>输入的高、宽，通常要么不变，要么<strong>减半</strong></li>
<li>转置卷积可以用来<strong>增大输入的高宽</strong></li>
</ul>
<h5 id="原因">原因</h5>
<ul>
<li>常用的卷积算子算到最后像素级别的数据被压缩到很小的范围</li>
<li>但是语义分割需要输出像素级别精度的类别，所以需要数据扩充</li>
</ul>
<figure>
<img src="https://zh-v2.d2l.ai/_images/trans_conv.svg" srcset="/img/loading.gif" lazyload
alt="../_images/trans_conv.svg" />
<figcaption aria-hidden="true">../_images/trans_conv.svg</figcaption>
</figure>
<h5 id="概念">概念</h5>
<ul>
<li>转置卷积是一种计算方式</li>
<li>卷积一般做下采样，转置卷积一般做上采样</li>
<li>意义在于
<ul>
<li>如果你使用某种卷积使得输入<span
class="math inline">\((h,w)\)</span>变为<span
class="math inline">\((h&#39;,w&#39;)\)</span></li>
<li>那么你可以使用同样超参数的转置卷积，使得输入<span
class="math inline">\((h&#39;,w&#39;)\)</span>变为<span
class="math inline">\((h,w)\)</span></li>
</ul></li>
<li>填充为0 步幅为1
<ul>
<li>计算方式1
<ul>
<li>将输入填充<code>k-1</code></li>
<li>将核矩阵上下、左右翻转</li>
<li>做正常卷积（填充0，步幅1）</li>
</ul></li>
<li>计算方式2
<ul>
<li>按转置卷积的方式计算</li>
</ul>
<figure>
<img src="/img/transposed-conv1.png" srcset="/img/loading.gif" lazyload alt="transposed-conv1" />
<figcaption aria-hidden="true">transposed-conv1</figcaption>
</figure></li>
</ul></li>
<li>填充为p 步幅为1
<ul>
<li>计算方式1
<ul>
<li>将输入填充<code>k-p-1</code></li>
<li>将核矩阵上下、左右翻转</li>
<li>然后做正常卷积（填充0，步幅1）</li>
</ul></li>
<li>计算方式2
<ul>
<li>按转置卷积的方式计算</li>
<li>在转置卷积的结果上去掉padding=1（外围一层）</li>
</ul>
<figure>
<img src="/img/transposed-conv2.png" srcset="/img/loading.gif" lazyload alt="transposed-conv2" />
<figcaption aria-hidden="true">transposed-conv2</figcaption>
</figure></li>
</ul></li>
<li>填充为p 步幅为s
<ul>
<li>计算方法1
<ul>
<li>在行和列之间插入<code>s-1</code>行或列</li>
<li>将输入填充<code>k-p-1</code></li>
<li>将核矩阵上下、左右翻转</li>
<li>然后做正常卷积（填充0，步幅1）</li>
</ul></li>
<li>计算方法2
<ul>
<li>按转置卷积的方式计算</li>
</ul>
<figure>
<img src="/img/transposed-conv3.png" srcset="/img/loading.gif" lazyload alt="transposed-conv3" />
<figcaption aria-hidden="true">transposed-conv3</figcaption>
</figure></li>
</ul></li>
<li>形状换算
<ul>
<li>输入高（宽）为<code>n</code>，核<code>k</code>，填充<code>p</code>，步幅<code>s</code></li>
<li>转置卷积：<code>n'=sn+k-2p-s</code>
<ul>
<li>卷积：<code>n'=[(n-k-2p+s)]/s</code></li>
</ul></li>
<li>如果让高、宽成倍增加
<ul>
<li><code>k=2p+s</code></li>
</ul></li>
</ul></li>
</ul>
<h5 id="总结-1">总结</h5>
<ul>
<li>转置卷积是一种变化了输入和核的卷积，用来达到上采样的目的</li>
<li>不等同于数学上的反卷积操作 ##### 案例</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 手撸版本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">trans_conv</span>(<span class="hljs-params">X,K</span>):<br>    h, w = K.shape<br>      <span class="hljs-comment"># 设置输出形状</span><br>    Y = torch.zeros((X.shape[<span class="hljs-number">0</span>]+h-<span class="hljs-number">1</span>,X.shape[<span class="hljs-number">1</span>]+w-<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X.shape[<span class="hljs-number">1</span>]):<br>            Y[i:i+h,j:j+w] += X[i,j]*K<br>    <span class="hljs-keyword">return</span> Y<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># API版本</span><br><span class="hljs-comment"># 设置转置卷积形状</span><br>tconv = nn.ConvTranspose2d(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,kernel_size=<span class="hljs-number">2</span>,bias=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># 设置转置卷积参数</span><br>tconv.weight = K<br><span class="hljs-comment"># 计算</span><br>tconv(X)<br></code></pre></td></tr></table></figure>
<h6 id="填充">填充</h6>
<p>与常规卷积不同，在转置卷积中，填充被应用于的输出（常规卷积将填充应用于输入）。
例如，当将高和宽两侧的填充数指定为1时，转置卷积的输出中将删除第一和最后的行与列。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 填补Padding</span><br><span class="hljs-comment"># Padding = 1</span><br><span class="hljs-comment"># 原过程：在“输出”的基础上 上下填补计算普通卷积得到“输入”</span><br><span class="hljs-comment"># 转置卷积过程：输入计算转置卷积再去掉上下填补的部分</span><br><span class="hljs-comment"># padding=1 把不含padding转置卷积的结果除掉padding</span><br>tconv = nn.ConvTranspose2d(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,kernel_size=<span class="hljs-number">2</span>,padding=<span class="hljs-number">1</span>,bias=<span class="hljs-literal">False</span>)<br>tconv.weigth.data = K<br>tconv(X)<br><br></code></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 步长Stride</span><br><br><span class="hljs-comment"># 步长输出计算公式 和卷积相反</span><br>tconv = nn.ConvTranspose2d(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,kernel_size=<span class="hljs-number">2</span>,bias=<span class="hljs-literal">False</span>)<br>tconv.weight.data = K<br>tconv(X)<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 与通道的关系</span><br>X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">16</span>, <span class="hljs-number">16</span>))<br>conv = nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>, stride=<span class="hljs-number">3</span>)<br>tconv = nn.ConvTranspose2d(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>, stride=<span class="hljs-number">3</span>)<br>tconv(conv(X)).shape == X.shape<br><br><span class="hljs-comment"># 若卷积的过程中不发生向下取整则成立</span><br></code></pre></td></tr></table></figure>
<h4 id="全卷积网络fcn">全卷积网络(FCN)</h4>
<h5 id="定义">定义</h5>
<p>全卷积网络将中间层特征图的高宽变换回输入图像的尺寸。
最后的通道维输出该位置对应像素的类别预测。</p>
<h5 id="构造">构造</h5>
<p>全卷积网络先使用卷积神经网络抽取图像特征，然后通过卷积层将通道数变换为类别个数，最后在通过转置卷积层将特征图的高和宽变换为输入图像的尺寸。
因此，模型输出与输入图像的高和宽相同，且最终输出通道包含了该空间位置像素的类别预测。</p>
<h5 id="特点-4">特点</h5>
<p>双线性插值常用于初始化转置卷积层</p>
<h5 id="代码-1">代码</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加载预训练模型，resnet18</span><br>pretrained_net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># resnet18 最后的全局平均池化层和全连接层不要</span><br>net = nn.Sequential(*<span class="hljs-built_in">list</span>(pretrained_net.children())[:-<span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义训练类别</span><br>num_classes = <span class="hljs-number">21</span><br><br><span class="hljs-comment"># 网络最后两层改为 </span><br><span class="hljs-comment"># in_channel 512 out_channel 21类别的1x1卷积层 把通道数从512降到21</span><br><span class="hljs-comment"># in_channel 21类别 out_channel 21类别 把h w 还原为 [320,480]</span><br>net.add_module(<span class="hljs-string">&#x27;final_conv&#x27;</span>, nn.Conv2d(<span class="hljs-number">512</span>, num_classes, kernel_size=<span class="hljs-number">1</span>))<br>net.add_module(<span class="hljs-string">&#x27;transpose_conv&#x27;</span>, nn.ConvTranspose2d(num_classes, num_classes,kernel_size=<span class="hljs-number">64</span>, padding=<span class="hljs-number">16</span>, stride=<span class="hljs-number">32</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 定义双线性上采样方法，用该方法初始化转置卷积的初始参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bilinear_kernel</span>(<span class="hljs-params">in_channels, out_channels, kernel_size</span>):<br>    factor = (kernel_size + <span class="hljs-number">1</span>) // <span class="hljs-number">2</span><br>    <span class="hljs-keyword">if</span> kernel_size % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:<br>        center = factor - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        center = factor - <span class="hljs-number">0.5</span><br>    og = (torch.arange(kernel_size).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>          torch.arange(kernel_size).reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>))<br>    filt = (<span class="hljs-number">1</span> - torch.<span class="hljs-built_in">abs</span>(og[<span class="hljs-number">0</span>] - center) / factor) * \<br>           (<span class="hljs-number">1</span> - torch.<span class="hljs-built_in">abs</span>(og[<span class="hljs-number">1</span>] - center) / factor)<br>    weight = torch.zeros((in_channels, out_channels,<br>                          kernel_size, kernel_size))<br>    weight[<span class="hljs-built_in">range</span>(in_channels), <span class="hljs-built_in">range</span>(out_channels), :, :] = filt<br>    <span class="hljs-keyword">return</span> weight<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化转置卷积层参数并应用参数</span><br>W = bilinear_kernel(num_classes, num_classes, <span class="hljs-number">64</span>)<br>net.transpose_conv.weight.data.copy_(W);<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 具体训练过程</span><br>batch_size, crop_size = <span class="hljs-number">32</span>, (<span class="hljs-number">320</span>, <span class="hljs-number">480</span>)<br>train_iter, test_iter = d2l.load_data_voc(batch_size, crop_size)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">inputs, targets</span>):<br>    <span class="hljs-keyword">return</span> F.cross_entropy(inputs, targets, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).mean(<span class="hljs-number">1</span>).mean(<span class="hljs-number">1</span>)<br><br>num_epochs, lr, wd, devices = <span class="hljs-number">5</span>, <span class="hljs-number">0.001</span>, <span class="hljs-number">1e-3</span>, d2l.try_all_gpus()<br>trainer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)<br>d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">inputs, targets</span>):<br>    <span class="hljs-keyword">return</span> F.cross_entropy(inputs, targets, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).mean(<span class="hljs-number">1</span>).mean(<span class="hljs-number">1</span>)<br><br>num_epochs, lr, wd, devices = <span class="hljs-number">5</span>, <span class="hljs-number">0.001</span>, <span class="hljs-number">1e-3</span>, d2l.try_all_gpus()<br>trainer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd)<br>d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 像素标号</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">label2image</span>(<span class="hljs-params">pred</span>):<br>    colormap = torch.tensor(d2l.VOC_COLORMAP, device=devices[<span class="hljs-number">0</span>])<br>    X = pred.long()<br>    <span class="hljs-keyword">return</span> colormap[X, :]<br><span class="hljs-comment"># 测试</span><br>voc_dir = d2l.download_extract(<span class="hljs-string">&#x27;voc2012&#x27;</span>, <span class="hljs-string">&#x27;VOCdevkit/VOC2012&#x27;</span>)<br>test_images, test_labels = d2l.read_voc_images(voc_dir, <span class="hljs-literal">False</span>)<br>n, imgs = <span class="hljs-number">4</span>, []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    crop_rect = (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>)<br>    X = torchvision.transforms.functional.crop(test_images[i], *crop_rect)<br>    pred = label2image(predict(X))<br>    imgs += [X.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>), pred.cpu(),<br>             torchvision.transforms.functional.crop(<br>                 test_labels[i], *crop_rect).permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)]<br>d2l.show_images(imgs[::<span class="hljs-number">3</span>] + imgs[<span class="hljs-number">1</span>::<span class="hljs-number">3</span>] + imgs[<span class="hljs-number">2</span>::<span class="hljs-number">3</span>], <span class="hljs-number">3</span>, n, scale=<span class="hljs-number">2</span>);<br></code></pre></td></tr></table></figure>
<h4 id="样式迁移学习">样式迁移学习</h4>
<figure>
<img src="/img/neural-style.svg" srcset="/img/loading.gif" lazyload alt="neural-style" />
<figcaption aria-hidden="true">neural-style</figcaption>
</figure>
<h5 id="思想">思想</h5>
<ul>
<li>一套网络复制三次，三个卷积层</li>
<li>合成图像的像素值是最后的训练目标</li>
<li>损失计算
<ul>
<li>合成图像与样式图像计算样式损失</li>
<li>合成图像与内容图像计算内容损失</li>
<li>最后损失用权重汇总为总变差损失作为优化目标</li>
</ul></li>
</ul>
<h5 id="代码-2">代码</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>d2l.set_figsize()<br><span class="hljs-comment"># 加载图片</span><br><span class="hljs-comment"># 内容图片</span><br>content_img = d2l.Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../data/banana-detection/bananas_train/images/753.png&#x27;</span>)<br>d2l.plt.imshow(content_img);<br><span class="hljs-comment"># 样式图片</span><br>style_img = d2l.Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../img/autumn-oak.jpg&#x27;</span>)<br>d2l.plt.imshow(style_img);<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">rgb_mean = torch.tensor([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>])<br>rgb_std = torch.tensor([<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br><span class="hljs-comment"># 图像预处理</span><br><span class="hljs-comment"># preprocess 把图像转为Tensor</span><br><span class="hljs-comment"># Compose里存了 Resize，ToTensor和Normalize 有点像Sequential</span><br><span class="hljs-comment"># ToTensor 自动/255了</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess</span>(<span class="hljs-params">img, image_shape</span>):<br>    transforms = torchvision.transforms.Compose([<br>        torchvision.transforms.Resize(image_shape),<br>        torchvision.transforms.ToTensor(),<br>        torchvision.transforms.Normalize(mean=rgb_mean, std=rgb_std)])<br>    <span class="hljs-keyword">return</span> transforms(img).unsqueeze(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># postprocess</span><br><span class="hljs-comment"># 把Tensor还原为图像</span><br><span class="hljs-comment"># [0,1] 大于1取1 小于0取0 </span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">img</span>):<br>    img = img[<span class="hljs-number">0</span>].to(rgb_std.device)<br>    img = torch.clamp(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>) * rgb_std + rgb_mean, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> torchvision.transforms.ToPILImage()(img.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加载预训练网络</span><br>pretrained_net = torchvision.models.vgg19(pretrained=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 从预训练网络中load我们所需要的层</span><br><span class="hljs-comment"># VGG19中 [0, 5, 10, 19, 28]层作为style_layers 抽取样式图像特征</span><br><span class="hljs-comment"># VGG19中 [25]层作为content_layers 抽取内容图像特征</span><br>style_layers, content_layers = [<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">19</span>, <span class="hljs-number">28</span>], [<span class="hljs-number">25</span>]<br><br><span class="hljs-comment"># 构建网络</span><br>net = nn.Sequential(*[pretrained_net.features[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span><br>                      <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>(content_layers + style_layers) + <span class="hljs-number">1</span>)])<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义特征抽取函数</span><br><span class="hljs-comment"># 逐层计算 保留每层style与content抽取的特征</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_features</span>(<span class="hljs-params">X, content_layers, style_layers</span>):<br>    contents = []<br>    styles = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(net)):<br>        X = net[i](X)<br>        <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> style_layers:<br>            styles.append(X)<br>        <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> content_layers:<br>            contents.append(X)<br>    <span class="hljs-keyword">return</span> contents, styles<br><br> <span class="hljs-comment"># 调用特征抽取函数，获取各层抽取的特征</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_contents</span>(<span class="hljs-params">image_shape, device</span>):<br>    <span class="hljs-comment"># 预处理得到原始Content图像Tensor</span><br>    content_X = preprocess(content_img, image_shape).to(device)<br>    <span class="hljs-comment"># 抽Contents特征</span><br>    contents_Y, _ = extract_features(content_X, content_layers, style_layers)<br>    <span class="hljs-keyword">return</span> content_X, contents_Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_styles</span>(<span class="hljs-params">image_shape, device</span>):<br>  	<span class="hljs-comment"># 预处理得到原始Style图像Tensor</span><br>    style_X = preprocess(style_img, image_shape).to(device)<br>    <span class="hljs-comment"># 抽Style图像特征</span><br>    _, styles_Y = extract_features(style_X, content_layers, style_layers)<br>    <span class="hljs-keyword">return</span> style_X, styles<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br><br><span class="hljs-comment">#内容损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">content_loss</span>(<span class="hljs-params">Y_hat, Y</span>):<br>    <span class="hljs-comment"># Y_hat content_Y 抽取的Contents特征Tensor</span><br>    <span class="hljs-comment"># Y: content_X 原始Content图像Tensor</span><br>    <span class="hljs-comment"># Y不需要计算梯度，Y.detach()可以写在外面</span><br>    <span class="hljs-keyword">return</span> torch.square(Y_hat - Y.detach()).mean()<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br><br><span class="hljs-comment"># 定格拉姆矩阵表达风格层输出的风格</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gram</span>(<span class="hljs-params">X</span>):<br>    num_channels, n = X.shape[<span class="hljs-number">1</span>], X.numel() // X.shape[<span class="hljs-number">1</span>]<br>    X = X.reshape((num_channels, n))<br>    <span class="hljs-keyword">return</span> torch.matmul(X, X.T) / (num_channels * n)<br><span class="hljs-comment"># 定义风格损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">style_loss</span>(<span class="hljs-params">Y_hat, gram_Y</span>):<br>    <span class="hljs-keyword">return</span> torch.square(gram(Y_hat) - gram_Y.detach()).mean()<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br><br><span class="hljs-comment"># 定义TV损失函数（全变分,total variation denosing）</span><br><span class="hljs-comment"># 能够使得临近的像素值相似</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tv_loss</span>(<span class="hljs-params">Y_hat</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * (torch.<span class="hljs-built_in">abs</span>(Y_hat[:, :, <span class="hljs-number">1</span>:, :] - Y_hat[:, :, :-<span class="hljs-number">1</span>, :]).mean() +<br>                  torch.<span class="hljs-built_in">abs</span>(Y_hat[:, :, :, <span class="hljs-number">1</span>:] - Y_hat[:, :, :, :-<span class="hljs-number">1</span>]).mean())<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br><br><span class="hljs-comment"># 综合三个损失函数计算方案</span><br><br>content_weight, style_weight, tv_weight = <span class="hljs-number">1</span>, <span class="hljs-number">1e4</span>, <span class="hljs-number">10</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram</span>):<br>    <span class="hljs-comment"># 分别计算内容损失、风格损失和全变分损失</span><br>    contents_l = [content_loss(Y_hat, Y) * content_weight <span class="hljs-keyword">for</span> Y_hat, Y <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>        contents_Y_hat, contents_Y)]<br>    styles_l = [style_loss(Y_hat, Y) * style_weight <span class="hljs-keyword">for</span> Y_hat, Y <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>        styles_Y_hat, styles_Y_gram)]<br>    tv_l = tv_loss(X) * tv_weight<br>    <span class="hljs-comment"># 对所有损失求和</span><br>    l = <span class="hljs-built_in">sum</span>(styles_l + contents_l + [tv_l])<br>    <span class="hljs-keyword">return</span> contents_l, styles_l, tv_l, l<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化合成图像</span><br><br><span class="hljs-comment"># 合成的图像是训练期间唯一需要更新的变量，将合成图像视为模型的参数</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SynthesizedImage</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, img_shape, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(SynthesizedImage, self).__init__(**kwargs)<br>        self.weight = nn.Parameter(torch.rand(*img_shape))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.weight<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义网络初始化函数 </span><br><span class="hljs-comment"># 提前计算风格层的格拉姆矩阵</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_inits</span>(<span class="hljs-params">X, device, lr, styles_Y</span>):<br>    gen_img = SynthesizedImage(X.shape).to(device)<br>    gen_img.weight.data.copy_(X.data)<br>    trainer = torch.optim.Adam(gen_img.parameters(), lr=lr)<br>    styles_Y_gram = [gram(Y) <span class="hljs-keyword">for</span> Y <span class="hljs-keyword">in</span> styles_Y]<br>    <span class="hljs-keyword">return</span> gen_img(), styles_Y_gram, trainer<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义训练函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch</span>):<br>    X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y)<br>    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, <span class="hljs-number">0.8</span>)<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>,<br>                            xlim=[<span class="hljs-number">10</span>, num_epochs],<br>                            legend=[<span class="hljs-string">&#x27;content&#x27;</span>, <span class="hljs-string">&#x27;style&#x27;</span>, <span class="hljs-string">&#x27;TV&#x27;</span>],<br>                            ncols=<span class="hljs-number">2</span>, figsize=(<span class="hljs-number">7</span>, <span class="hljs-number">2.5</span>))<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        trainer.zero_grad()<br>        contents_Y_hat, styles_Y_hat = extract_features(<br>            X, content_layers, style_layers)<br>        contents_l, styles_l, tv_l, l = compute_loss(<br>            X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram)<br>        l.backward()<br>        trainer.step()<br>        scheduler.step()<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            animator.axes[<span class="hljs-number">1</span>].imshow(postprocess(X))<br>            animator.add(epoch + <span class="hljs-number">1</span>, [<span class="hljs-built_in">float</span>(<span class="hljs-built_in">sum</span>(contents_l)),<br>                                     <span class="hljs-built_in">float</span>(<span class="hljs-built_in">sum</span>(styles_l)), <span class="hljs-built_in">float</span>(tv_l)])<br>    <span class="hljs-keyword">return</span> X<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 开始训练</span><br>device, image_shape = d2l.try_gpu(), (<span class="hljs-number">300</span>, <span class="hljs-number">450</span>)<br>net = net.to(device)<br>content_X, contents_Y = get_contents(image_shape, device)<br>_, styles_Y = get_styles(image_shape, device)<br>output = train(content_X, contents_Y, styles_Y, device, <span class="hljs-number">0.3</span>, <span class="hljs-number">500</span>, <span class="hljs-number">50</span>)<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Notes/" class="category-chain-item">Notes</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/DeepLearning/">#DeepLearning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>深度学习 计算机视觉 笔记</div>
      <div>https://anonymouslosty.github.io/2023/06/18/深度学习 计算机视觉 笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Ling yi</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年6月18日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2023年7月5日</div>
        </div>
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/07/04/Kubernetes-%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96/" title="Kubernetes 配置与初始化">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kubernetes 配置与初始化</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/06/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20GPU%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%BA%A6%E7%AC%94%E8%AE%B0/" title="深度学习 GPU与模型迁移 笔记">
                        <span class="hidden-mobile">深度学习 GPU与模型迁移 笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":true,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
